{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vinay/anaconda3/envs/tensor/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3058: DtypeWarning: Columns (746,835) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n",
      "/home/vinay/anaconda3/envs/tensor/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3058: DtypeWarning: Columns (700,731,740,752,761,789,811,820,829,841,850) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "train=pd.read_csv('/home/vinay/Downloads/HDFC_ML/DataSet/Train.csv')\n",
    "test=pd.read_csv('/home/vinay/Downloads/HDFC_ML/DataSet/Test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 17521 entries, 0 to 17520\n",
      "Columns: 2395 entries, Col1 to Col2397\n",
      "dtypes: float64(844), int64(1548), object(3)\n",
      "memory usage: 320.2+ MB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20442 entries, 0 to 20441\n",
      "Columns: 2394 entries, Col1 to Col2397\n",
      "dtypes: float64(837), int64(1545), object(12)\n",
      "memory usage: 373.4+ MB\n"
     ]
    }
   ],
   "source": [
    "test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20442, 2394)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17521, 2395)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Col1', 'Col747', 'Col836'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "trainobjects = train.select_dtypes(include=[object])\n",
    "print(trainobjects.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Col1', 'Col702', 'Col733', 'Col742', 'Col754', 'Col763', 'Col791',\n",
      "       'Col813', 'Col822', 'Col831', 'Col843', 'Col852'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "testobjects = test.select_dtypes(include=[object])\n",
    "print(testobjects.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Col1', 'Col702', 'Col733', 'Col742', 'Col747', 'Col754', 'Col763',\n",
      "       'Col791', 'Col813', 'Col822', 'Col831', 'Col836', 'Col843', 'Col852'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "rcolumns=trainobjects+testobjects\n",
    "print(rcolumns.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20442, 14)\n"
     ]
    }
   ],
   "source": [
    "print(rcolumns.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=train['Col2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17521, 2380)\n"
     ]
    }
   ],
   "source": [
    "train=train.drop(columns=rcolumns.columns)\n",
    "train.drop('Col2', axis=1, inplace=True)\n",
    "print(train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "nan_cols = [i for i in x.columns if x[i].isnull().any()]\n",
    "print(len(nan_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17521, 2380) (17521,)\n"
     ]
    }
   ],
   "source": [
    "print(x.shape,y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3) # 70% training and 30% test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zeros  : 4742\n",
      "Ones   : 515\n"
     ]
    }
   ],
   "source": [
    "zero=one=0\n",
    "for val in y_test:\n",
    "    if val==0:\n",
    "        zero+=1\n",
    "    else:\n",
    "        one+=1\n",
    "print(\"Zeros  :\",zero)\n",
    "print(\"Ones   :\",one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {'n_estimators': [90,100,150,200]}\n",
    "#Create a Gaussian Classifier\n",
    "clf=RandomForestClassifier()\n",
    "rf_clf=GridSearchCV(clf,param_grid)\n",
    "rf_clf.fit(x_train, y_train)\n",
    "print(rf_clf.best_params_)\n",
    "print(rf_clf.best_score_)\n",
    "y_pred=rf_clf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8997527106714857\n",
      "(0.7069506268632335, 0.5202954689632634, 0.5152274089336255, None)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      1.00      0.95      4729\n",
      "           1       0.51      0.05      0.08       528\n",
      "\n",
      "    accuracy                           0.90      5257\n",
      "   macro avg       0.71      0.52      0.52      5257\n",
      "weighted avg       0.86      0.90      0.86      5257\n",
      "\n",
      "[[4706   23]\n",
      " [ 504   24]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
    "#Train the model using the training sets y_pred=clf.predict(X_test)\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "print(precision_recall_fscore_support(y_test,y_pred,average='macro'))\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test,y_pred))\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20442, 2394)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        RIGD58ZWD\n",
       "1        RIH660YDS\n",
       "2        RIH660Q96\n",
       "3        RIYDO15W1\n",
       "4        RIYBGC1ZD\n",
       "           ...    \n",
       "20437     OL0I6O5R\n",
       "20438     OL0I65ZW\n",
       "20439     OL0I6CXW\n",
       "20440       O2VIUO\n",
       "20441     M7VKV5QD\n",
       "Name: Col1, Length: 20442, dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.Col1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    RIGD58ZWD\n",
      "1    RIH660YDS\n",
      "2    RIH660Q96\n",
      "3    RIYDO15W1\n",
      "4    RIYBGC1ZD\n",
      "Name: Col1, dtype: object\n"
     ]
    }
   ],
   "source": [
    "testid=test['Col1']\n",
    "print(testid.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "test=test.drop(columns=rcolumns.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20442, 2380)\n"
     ]
    }
   ],
   "source": [
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "test.fillna(0, inplace=True)\n",
    "nan_cols = [i for i in test.columns if test[i].isnull().any()]\n",
    "print(len(nan_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFittedError",
     "evalue": "This RandomForestClassifier instance is not fitted yet. Call 'fit' with appropriate arguments before using this method.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-5a7a3f7a579f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresult\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/tensor/lib/python3.7/site-packages/sklearn/ensemble/forest.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m         \"\"\"\n\u001b[0;32m--> 545\u001b[0;31m         \u001b[0mproba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    546\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensor/lib/python3.7/site-packages/sklearn/ensemble/forest.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    584\u001b[0m             \u001b[0mclasses\u001b[0m \u001b[0mcorresponds\u001b[0m \u001b[0mto\u001b[0m \u001b[0mthat\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mattribute\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m         \"\"\"\n\u001b[0;32m--> 586\u001b[0;31m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'estimators_'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m         \u001b[0;31m# Check data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensor/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_is_fitted\u001b[0;34m(estimator, attributes, msg, all_or_any)\u001b[0m\n\u001b[1;32m    912\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    913\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mall_or_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mattr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mattributes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 914\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mNotFittedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'name'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    915\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotFittedError\u001b[0m: This RandomForestClassifier instance is not fitted yet. Call 'fit' with appropriate arguments before using this method."
     ]
    }
   ],
   "source": [
    "result=clf.predict(test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero=one=0\n",
    "for val in result:\n",
    "    if val==0:\n",
    "        zero+=1\n",
    "    else:\n",
    "        one+=1\n",
    "print(\"Zeros  :\",zero)\n",
    "print(\"Ones   :\",one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions=np.asarray([testid,result])\n",
    "predictions=predictions.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(predictions,columns=['Col1','Col2']).to_csv(\"/home/vinay/Downloads/HDFC_ML/DataSet/Predictions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "param_grid = {'n_neighbors': [10,50,100,200,300]}\n",
    "knn = KNeighborsClassifier()\n",
    "knn_cv = GridSearchCV(knn, param_grid)\n",
    "knn_cv.fit(x_train, y_train)\n",
    "print(knn_cv.best_params_)\n",
    "print(knn_cv.best_score_)\n",
    "y_pred=clf.predict(x_test)\n",
    "from sklearn import metrics\n",
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result=clf.predict(test)\n",
    "predictions=np.asarray([testid,result])\n",
    "predictions=predictions.T\n",
    "pd.DataFrame(predictions,columns=['Col1','Col2']).to_csv(\"/home/vinay/Downloads/HDFC_ML/DataSet/Predictionsknn.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 1111: 0.8990014265335236\n",
      "(0.6886736599213639, 0.5223965991984546, 0.5194166860330003, None)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.99      0.95      3153\n",
      "           1       0.47      0.05      0.09       352\n",
      "\n",
      "    accuracy                           0.90      3505\n",
      "   macro avg       0.69      0.52      0.52      3505\n",
      "weighted avg       0.86      0.90      0.86      3505\n",
      "\n",
      "[[3133   20]\n",
      " [ 334   18]]\n",
      "Accuracy 1112: 0.9009985734664765\n",
      "(0.7558125015608221, 0.5184591514574863, 0.5111841245918111, None)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      1.00      0.95      3153\n",
      "           1       0.61      0.04      0.07       352\n",
      "\n",
      "    accuracy                           0.90      3505\n",
      "   macro avg       0.76      0.52      0.51      3505\n",
      "weighted avg       0.87      0.90      0.86      3505\n",
      "\n",
      "[[3144    9]\n",
      " [ 338   14]]\n",
      "Accuracy 1113: 0.9001426533523538\n",
      "(0.7183213429256594, 0.5205071648934637, 0.5154816785523577, None)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      1.00      0.95      3153\n",
      "           1       0.53      0.05      0.08       352\n",
      "\n",
      "    accuracy                           0.90      3505\n",
      "   macro avg       0.72      0.52      0.52      3505\n",
      "weighted avg       0.87      0.90      0.86      3505\n",
      "\n",
      "[[3139   14]\n",
      " [ 336   16]]\n",
      "Accuracy 1114: 0.9004279600570614\n",
      "(0.7234458624948539, 0.5244513702678546, 0.5227480306082359, None)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.99      0.95      3153\n",
      "           1       0.54      0.05      0.10       352\n",
      "\n",
      "    accuracy                           0.90      3505\n",
      "   macro avg       0.72      0.52      0.52      3505\n",
      "weighted avg       0.87      0.90      0.86      3505\n",
      "\n",
      "[[3137   16]\n",
      " [ 333   19]]\n",
      "Accuracy 1115: 0.9018544935805991\n",
      "(0.7925312557095503, 0.5201967642649137, 0.5141877234207838, None)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      1.00      0.95      3153\n",
      "           1       0.68      0.04      0.08       352\n",
      "\n",
      "    accuracy                           0.90      3505\n",
      "   macro avg       0.79      0.52      0.51      3505\n",
      "weighted avg       0.88      0.90      0.86      3505\n",
      "\n",
      "[[3146    7]\n",
      " [ 337   15]]\n"
     ]
    }
   ],
   "source": [
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "sss = StratifiedShuffleSplit(n_splits=5, test_size=0.2, random_state=0)\n",
    "xclas = XGBClassifier()  # and for classifier  \n",
    "i=1111\n",
    "for train_index, test_index in sss.split(x, y):\n",
    "    x_train, x_test = x.iloc[train_index], x.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    xclas.fit(x_train, y_train)  \n",
    "    y_pred=xclas.predict(x_test)\n",
    "    print(\"Accuracy \"+str(i)+\":\",metrics.accuracy_score(y_test, y_pred))\n",
    "    result=xclas.predict(test)\n",
    "    print(precision_recall_fscore_support(y_test,y_pred,average='macro'))\n",
    "    print(classification_report(y_test,y_pred))\n",
    "    print(confusion_matrix(y_test,y_pred))\n",
    "    predictions=np.asarray([testid,result])\n",
    "    predictions=predictions.T\n",
    "    pd.DataFrame(predictions,columns=['Col1','Col2']).to_csv(\"/home/vinay/Downloads/HDFC_ML/DataSet/Predictionsxgsss\"+str(i)+\".csv\")\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result=clf.predict(test)\n",
    "predictions=np.asarray([testid,result])\n",
    "predictions=predictions.T\n",
    "\n",
    "#pd.DataFrame(predictions,columns=['Col1','Col2']).to_csv(\"/home/vinay/Downloads/HDFC_ML/DataSet/Predictionsxg.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from xgboost.sklearn import XGBClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, stratify=y,test_size=0.25)\n",
    "xclas = AdaBoostClassifier()  # and for classifier  \n",
    "xclas.fit(x_train, y_train)  \n",
    "y_pred=xclas.predict(x_test)\n",
    "print(\"Accuracy :\",metrics.accuracy_score(y_test, y_pred))\n",
    "result=clf.predict(test)\n",
    "predictions=np.asarray([testid,result])\n",
    "predictions=predictions.T\n",
    "print(predictions[:5])\n",
    "#pd.DataFrame(predictions,columns=['Col1','Col2']).to_csv(\"/home/vinay/Downloads/HDFC_ML/DataSet/Predictionsxgsss.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.7069506268632335, 0.5202954689632634, 0.5152274089336255, None)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      1.00      0.95      4729\n",
      "           1       0.51      0.05      0.08       528\n",
      "\n",
      "    accuracy                           0.90      5257\n",
      "   macro avg       0.71      0.52      0.52      5257\n",
      "weighted avg       0.86      0.90      0.86      5257\n",
      "\n",
      "[[4706   23]\n",
      " [ 504   24]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "print(precision_recall_fscore_support(y_test,y_pred,average='macro'))\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test,y_pred))\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#Create a Gaussian Classifier\n",
    "clf=RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "cv = cross_val_score(clf, x, y, cv=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
